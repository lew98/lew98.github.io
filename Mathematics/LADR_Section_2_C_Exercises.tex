\documentclass[12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{geometry}
\usepackage{amsfonts}
\usepackage{mathrsfs}
\usepackage{bm}
\usepackage{hyperref}
\usepackage[dvipsnames]{xcolor}
\usepackage{enumitem}
\usepackage{mathtools}
\usepackage{changepage}
\usepackage{lipsum}
\usepackage{tikz}
\usetikzlibrary{matrix}
\usepackage{tikz-cd}
\usepackage[nameinlink]{cleveref}
\geometry{
headheight=15pt,
left=60pt,
right=60pt
}
\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhf{}
\lhead{}
\chead{Section 2.C Exercises}
\rhead{\thepage}
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    urlcolor=blue
}

\theoremstyle{definition}
\newtheorem*{remark}{Remark}

\newtheoremstyle{exercise}
    {}
    {}
    {}
    {}
    {\bfseries}
    {.}
    { }
    {\thmname{#1}\thmnumber{#2}\thmnote{ (#3)}}
\theoremstyle{exercise}
\newtheorem{exercise}{Exercise 2.C.}

\newtheoremstyle{solution}
    {}
    {}
    {}
    {}
    {\itshape\color{magenta}}
    {.}
    { }
    {\thmname{#1}\thmnote{ #3}}
\theoremstyle{solution}
\newtheorem*{solution}{Solution}

\Crefformat{exercise}{#2Exercise 2.C.#1#3}

\newcommand{\poly}{\mathcal{P}}
\newcommand{\ts}{\textsuperscript}
\newcommand{\Span}{\text{span}}
\newcommand{\setcomp}[1]{#1^{\mathsf{c}}}
\newcommand{\N}{\mathbf{N}}
\newcommand{\Z}{\mathbf{Z}}
\newcommand{\Q}{\mathbf{Q}}
\newcommand{\R}{\mathbf{R}}
\newcommand{\C}{\mathbf{C}}
\newcommand{\F}{\mathbf{F}}

\DeclarePairedDelimiter\abs{\lvert}{\rvert}
% Swap the definition of \abs* and \norm*, so that \abs
% and \norm resizes the size of the brackets, and the 
% starred version does not.
\makeatletter
\let\oldabs\abs
\def\abs{\@ifstar{\oldabs}{\oldabs*}}
%
\let\oldnorm\norm
\def\norm{\@ifstar{\oldnorm}{\oldnorm*}}
\makeatother

\setlist[enumerate,1]{label={(\alph*)}}

\begin{document}

\section{Section 2.C Exercises}

Exercises with solutions from Section 2.C of \hyperlink{ladr}{[LADR]}.

\begin{exercise}
\label{ex:1}
    Suppose \( V \) is finite-dimensional and \( U \) is a subspace of \( V \) such that \( \dim U = \dim V \). Prove that \( U = V \).
\end{exercise}

\begin{solution}
    \( U \) is also finite-dimensional by 2.26, so \( U \) has a basis \( B \) by 2.32. Since \( B \) has length \( \dim U = \dim V \) and \( B \) is linearly independent, \( B \) is a basis of \( V \) by 2.39. It follows that \( V = \Span\,B = U \).
\end{solution}

\begin{exercise}
\label{ex:2}
    Show that the subspaces of \( \R^2 \) are precisely \( \{ 0 \}, \R^2, \) and all lines in \( \R^2 \) through the origin.
\end{exercise}

\begin{solution}
    It is easily verified that \( \{ 0 \}, \R^2, \) and all lines in \( \R^2 \) through the origin are indeed subspaces of \( \R^2 \). Suppose that \( U \) is a subspace of \( \R^2 \). Then since \( \dim \R^2 = 2 \), by 2.38 it must be the case that \( \dim U \in \{ 0, 1, 2 \} \). If \( \dim U = 0 \) then \( U = \{ 0 \} \) and if \( \dim U = 2 \) then \( U = \R^2 \), by \Cref{ex:1}. Suppose therefore that \( \dim U = 1 \). Then there exists a basis \( u \) of \( U \), so that \( U = \Span(u) = \{ \lambda u : \lambda \in \R \} \), and we see that \( U \) is a line through the origin with direction vector \( u \) (this is indeed a direction vector, i.e.\ \( u \neq 0 \), since the list \( u \) is linearly independent). We have now shown that if \( U \) is a subspace of \( \R^2 \), then \( U \) is either \( \{ 0 \}, \R^2, \) or a line in \( \R^2 \) through the origin. We may conclude that these are precisely the subspaces of \( \R^2 \).
\end{solution}

\begin{exercise}
\label{ex:3}
    Show that the subspaces of \( \R^3 \) are precisely \( \{ 0 \}, \R^3, \) all lines in \( \R^3 \) through the origin, and all planes in \( \R^3 \) through the origin.
\end{exercise}

\begin{solution}
    It is easily verified that \( \{ 0 \}, \R^3, \) all lines in \( \R^3 \) through the origin, and all planes in \( \R^3 \) through the origin are indeed subspaces of \( \R^3 \). Suppose that \( U \) is a subspace of \( \R^3 \). Then since \( \dim \R^3 = 3 \), by 2.38 it must be the case that \( \dim U \in \{ 0, 1, 2, 3 \} \). If \( \dim U = 0 \) then \( U = \{ 0 \} \) and if \( \dim U = 3 \) then \( U = \R^3 \), by \Cref{ex:1}. Suppose therefore that \( \dim U = 1 \). Then there exists a basis \( u \) of \( U \), so that \( U = \Span(u) = \{ \lambda u : \lambda \in \R \} \), and we see that \( U \) is a line through the origin with direction vector \( u \) (this is indeed a direction vector, i.e.\ \( u \neq 0 \), since the list \( u \) is linearly independent). Now suppose that \( \dim U = 2 \). Then there exists a basis \( u_1, u_2 \) of \( U \), so that \( U = \Span(u_1, u_2) = \{ \lambda_1 u_1 + \lambda_2 u_2 : \lambda_1, \lambda_2 \in \R \} \), and we see that \( U \) is a plane through the origin with direction vectors \( u_1 \) and \( u_2 \) (these are indeed distinct direction vectors, i.e.\ neither is a scalar multiple of the other, since the list \( u_1, u_2 \) is linearly independent). We have now shown that if \( U \) is a subspace of \( \R^3 \), then \( U \) is either \( \{ 0 \}, \R^3, \) a line in \( \R^3 \) through the origin, or a plane in \( \R^3 \) through the origin. We may conclude that these are precisely the subspaces of \( \R^3 \).
\end{solution}

\begin{exercise}
\label{ex:4}
    \begin{enumerate}
        \item Let \( U = \{ p \in \poly_4(\F) : p(6) = 0 \} \). Find a basis of \( U \).

        \item Extend the basis in part (a) to a basis of \( \poly_4(\F) \).

        \item Find a subspace \( W \) of \( \poly_4(\F) \) such that \( \poly_4(\F) = U \oplus W \).
    \end{enumerate}
\end{exercise}

\begin{solution}
    \begin{enumerate}
        \item Let \( B = x - 6, (x - 6)^2, (x - 6)^3, (x - 6)^4 \); clearly each vector in \( B \) belongs to \( U \). Suppose we have scalars \( a_1, a_2, a_3, a_4 \) such that
        \[
            a_1 (x - 6) + a_2 (x - 6)^2 + a_3 (x - 6)^3 + a_4 (x - 6)^4 = 0
        \]
        for each \( x \in \F \). Using the reasoning of Example 2.41, we see that the left-hand side has an \( a_4 x^4 \) term but the right-hand side has no \( x^4 \) term. Hence we must have \( a_4 = 0 \), and a similar argument with the \( x^3 \) term, the \( x^2 \) term, and the \( x \) term shows that \( a_3 = a_2 = a_1 = 0 \). It follows that \( B \) is linearly independent and thus by 2.23 we have \( \dim U \geq 4 \). We also have \( \dim U \leq \dim \poly_4(\F) = 5 \) by 2.38. However, it cannot be the case that \( \dim U = 5 \), since by \Cref{ex:1} this would imply that \( U = \poly_4(\F) \), but \( U \neq \poly_4(\F) \) since not all polynomials \( p \in \poly_4(\F) \) satisfy \( p(6) = 0 \). So \( \dim U = 4 \) and by 2.39 we may conclude that \( B \) is a basis of \( U \).

        \item We claim that \( 1 \not\in \Span\,B \). To see this, suppose that we have scalars \( a_1, a_2, a_3, a_4 \) such that
        \[
            a_1 (x - 6) + a_2 (x - 6)^2 + a_3 (x - 6)^3 + a_4 (x - 6)^4 = 1
        \]
        for each \( x \in \F \). The same argument used in part (a) shows that we must have \( a_4 = a_3 = a_2 = a_1 = 0 \) and so we arrive at the contradiction \( 0 = 1 \). Thus \( 1 \not\in \Span\,B \), so the list \( B' := 1, x - 6, (x - 6)^2, (x - 6)^3, (x - 6)^4 \) is linearly independent by \href{https://lew98.github.io/Mathematics/LADR_Section_2_A_Exercises.pdf}{Exercise 2.A.11}. Then since \( \dim \poly_4(\F) = 5 \), 2.42 allows us to conclude that \( B' \) is a basis of \( \poly_4(\F) \).

        \item Let \( W = \Span(1) \), i.e.\ the subspace of all constant polynomials. As the proof of 2.34 shows, we then have \( \poly_4(\F) = U \oplus W \).
    \end{enumerate}
\end{solution}

\begin{exercise}
\label{ex:5}
    \begin{enumerate}
        \item Let \( U = \{ p \in \poly_4(\R) : p''(6) = 0 \} \). Find a basis of \( U \).

        \item Extend the basis in part (a) to a basis of \( \poly_4(\R) \).

        \item Find a subspace \( W \) of \( \poly_4(\R) \) such that \( \poly_4(\R) = U \oplus W \).
    \end{enumerate}
\end{exercise}
    
\begin{solution}
    \begin{enumerate}
        \item Let \( B = 1, x, (x - 6)^3, (x - 6)^4 \); clearly each vector in \( B \) belongs to \( U \). Suppose we have scalars \( a_0, a_1, a_3, a_4 \) such that
        \[
            a_0 + a_1 x + a_3 (x - 6)^3 + a_4 (x - 6)^4 = 0
        \]
        for each \( x \in \F \). Using the reasoning of Example 2.41, we see that the left-hand side has an \( a_4 x^4 \) term but the right-hand side has no \( x^4 \) term. Hence we must have \( a_4 = 0 \), and a similar argument with the \( x^3 \) term, the \( x \) term, and the constant term shows that \( a_3 = a_1 = a_0 = 0 \). It follows that \( B \) is linearly independent and thus by 2.23 we have \( \dim U \geq 4 \). We also have \( \dim U \leq 5 \) by 2.38. However, it cannot be the case that \( \dim U = 5 \), since by \Cref{ex:1} this would imply that \( U = \poly_4(\R) \), but \( U \neq \poly_4(\R) \) since not all polynomials \( p \in \poly_4(\R) \) satisfy \( p''(6) = 0 \). So \( \dim U = 4 \) and by 2.39 we may conclude that \( B \) is a basis of \( U \).

        \item We claim that \( x^2 \not\in \Span\,B \). To see this, suppose that we have scalars \( a_0, a_1, a_3, a_4 \) such that
        \[
            a_0 + a_1 x + a_3 (x - 6)^3 + a_4 (x - 6)^4 = x^2
        \]
        for each \( x \in \F \). The same argument used in part (a) shows that we must have \( a_4 = a_3 = a_1 = a_0 = 0 \) and so we arrive at the contradiction \( 0 = x^2 \) for every \( x \in \F \). Thus \( x^2 \not\in \Span\,B \), so the list \( B' := 1, x, x^2, (x - 6)^3, (x - 6)^4 \) is linearly independent by \href{https://lew98.github.io/Mathematics/LADR_Section_2_A_Exercises.pdf}{Exercise 2.A.11}. Then since \( \dim \poly_4(\R) = 5 \), 2.42 allows us to conclude that \( B' \) is a basis of \( \poly_4(\R) \).

        \item Let \( W = \Span(x^2) \). As the proof of 2.34 shows, we then have \( \poly_4(\R) = U \oplus W \).
    \end{enumerate}
\end{solution}

\begin{exercise}
\label{ex:6}
    \begin{enumerate}
        \item Let \( U = \{ p \in \poly_4(\F) : p(2) = p(5) \} \). Find a basis of \( U \).

        \item Extend the basis in part (a) to a basis of \( \poly_4(\F) \).

        \item Find a subspace \( W \) of \( \poly_4(\F) \) such that \( \poly_4(\F) = U \oplus W \).
    \end{enumerate}
\end{exercise}
    
\begin{solution}
    \begin{enumerate}
        \item Let \( B = 1, (x - 2)(x - 5), (x - 2)^2 (x - 5), (x - 2)^2 (x - 5)^2 \); clearly each vector in \( B \) belongs to \( U \). Suppose we have scalars \( a_0, a_2, a_3, a_4 \) such that
        \[
            a_0 + a_2 (x - 2)(x - 5) + a_3 (x - 2)^2 (x - 5) + a_4 (x - 2)^2 (x - 5)^2 = 0
        \]
        for each \( x \in \F \). Using the reasoning of Example 2.41, we see that the left-hand side has an \( a_4 x^4 \) term but the right-hand side has no \( x^4 \) term. Hence we must have \( a_4 = 0 \), and a similar argument with the \( x^3 \) term, the \( x^2 \) term, and the constant term shows that \( a_3 = a_2 = a_0 = 0 \). It follows that \( B \) is linearly independent and thus by 2.23 we have \( \dim U \geq 4 \). We also have \( \dim U \leq 5 \) by 2.38. However, it cannot be the case that \( \dim U = 5 \), since by \Cref{ex:1} this would imply that \( U = \poly_4(\F) \), but \( U \neq \poly_4(\F) \) since not all polynomials \( p \in \poly_4(\F) \) satisfy \( p(2) = p(5) \). So \( \dim U = 4 \) and by 2.39 we may conclude that \( B \) is a basis of \( U \).

        \item We claim that \( x \not\in \Span\,B \). To see this, suppose that we have scalars \( a_0, a_2, a_3, a_4 \) such that
        \[
            a_0 + a_2 (x - 2)(x - 5) + a_3 (x - 2)^2 (x - 5) + a_4 (x - 2)^2 (x - 5)^2 = x
        \]
        for each \( x \in \F \). The same argument used in part (a) shows that we must have \( a_4 = a_3 = a_2 = a_0 = 0 \) and so we arrive at the contradiction \( 0 = x \) for every \( x \in \F \). Thus \( x \not\in \Span\,B \), so the list \( B' := 1, x, (x - 2)(x - 5), (x - 2)^2 (x - 5), (x - 2)^2 (x - 5)^2 \) is linearly independent by \href{https://lew98.github.io/Mathematics/LADR_Section_2_A_Exercises.pdf}{Exercise 2.A.11}. Then since \( \dim \poly_4(\F) = 5 \), 2.42 allows us to conclude that \( B' \) is a basis of \( \poly_4(\F) \).

        \item Let \( W = \Span(x) \). As the proof of 2.34 shows, we then have \( \poly_4(\F) = U \oplus W \).
    \end{enumerate}
\end{solution}

\begin{exercise}
\label{ex:7}
    \begin{enumerate}
        \item Let \( U = \{ p \in \poly_4(\F) : p(2) = p(5) = p(6) \} \). Find a basis of \( U \).

        \item Extend the basis in part (a) to a basis of \( \poly_4(\F) \).

        \item Find a subspace \( W \) of \( \poly_4(\F) \) such that \( \poly_4(\F) = U \oplus W \).
    \end{enumerate}
\end{exercise}
    
\begin{solution}
    \begin{enumerate}
        \item Let \( B = 1, (x - 2)(x - 5)(x - 6), (x - 2)^2 (x - 5) (x - 6) \); clearly each vector in \( B \) belongs to \( U \). Suppose we have scalars \( a_0, a_3, a_4 \) such that
        \[
            a_0 + a_3 (x - 2)(x - 5)(x - 6) + a_4 (x - 2)^2 (x - 5) (x - 6) = 0
        \]
        for each \( x \in \F \). Using the reasoning of Example 2.41, we see that the left-hand side has an \( a_4 x^4 \) term but the right-hand side has no \( x^4 \) term. Hence we must have \( a_4 = 0 \), and a similar argument with the \( x^3 \) term and the constant term shows that \( a_3 = a_0 = 0 \). It follows that \( B \) is linearly independent and thus by 2.23 we have \( \dim U \geq 3 \). Note that \( U \) is a subspace of the subspace from \Cref{ex:6}, which has dimension 4, so we also have \( \dim U \leq 4 \) by 2.38. However, it cannot be the case that \( \dim U = 4 \), since by \Cref{ex:1} this would imply that \( U \) was equal to the subspace of \Cref{ex:6}, but this cannot be true since, for example, \( p(x) = (x - 2)(x - 5) \) satisfies \( p(2) = p(5) \) but does not satisfy \( p(2) = p(5) = p(6) \). So \( \dim U = 4 \) and by 2.39 we may conclude that \( B \) is a basis of \( U \).

        \item We claim that \( x \not\in \Span\,B \). To see this, suppose that we have scalars \( a_0, a_3, a_4 \) such that
        \[
            a_0 + a_3 (x - 2)(x - 5)(x - 6) + a_4 (x - 2)^2 (x - 5) (x - 6) = x
        \]
        for each \( x \in \F \). The same argument used in part (a) shows that we must have \( a_4 = a_3 = a_0 = 0 \) and so we arrive at the contradiction \( 0 = x \) for every \( x \in \F \). Thus \( x \not\in \Span\,B \), so the list \( B' := 1, x, (x - 2)(x - 5)(x - 6), (x - 2)^2 (x - 5) (x - 6) \) is linearly independent by \href{https://lew98.github.io/Mathematics/LADR_Section_2_A_Exercises.pdf}{Exercise 2.A.11}.
        
        Next we claim that \( x^2 \not\in \Span\,B' \). To see this, suppose that we have scalars \( a_0, a_1, a_3, a_4 \) such that
        \[
            a_0 + a_1 x + a_3 (x - 2)(x - 5)(x - 6) + a_4 (x - 2)^2 (x - 5) (x - 6) = x^2
        \]
        for each \( x \in \F \). The same argument used in part (a) shows that we must have \( a_4 = a_3 = a_1 = a_0 = 0 \) and so we arrive at the contradiction \( 0 = x^2 \) for every \( x \in \F \). Thus \( x^2 \not\in \Span\,B' \), so the list \( B'' := 1, x, x^2, (x - 2)(x - 5)(x - 6), (x - 2)^2 (x - 5) (x - 6) \) is linearly independent by \href{https://lew98.github.io/Mathematics/LADR_Section_2_A_Exercises.pdf}{Exercise 2.A.11}.

        Then since \( \dim \poly_4(\F) = 5 \), 2.42 allows us to conclude that \( B'' \) is a basis of \( \poly_4(\F) \).

        \item Let \( W = \Span(x, x^2) \). As the proof of 2.34 shows, we then have \( \poly_4(\F) = U \oplus W \).
    \end{enumerate}
\end{solution}

\begin{exercise}
\label{ex:8}
    \begin{enumerate}
        \item Let \( U = \{ p \in \poly_4(\R) : \int_{-1}^1 p = 0 \} \). Find a basis of \( U \).

        \item Extend the basis in part (a) to a basis of \( \poly_4(\R) \).

        \item Find a subspace \( W \) of \( \poly_4(\R) \) such that \( \poly_4(\F) = U \oplus W \).
    \end{enumerate}
\end{exercise}
    
\begin{solution}
    \begin{enumerate}
        \item Let \( B = x, x^2 - \tfrac{1}{3}, x^3, x^4 - \tfrac{1}{5} \); it is easily verified that each vector in \( B \) belongs to \( U \). Suppose we have scalars \( a_1, a_2, a_3, a_4 \) such that
        \[
            a_1 x + a_2 (x^2 - \tfrac{1}{3}) + a_3 x^3 + a_4 (x^4 - \tfrac{1}{5}) = 0
        \]
        for each \( x \in \F \). Using the reasoning of Example 2.41, we see that the left-hand side has an \( a_4 x^4 \) term but the right-hand side has no \( x^4 \) term. Hence we must have \( a_4 = 0 \), and a similar argument with the \( x^3 \) term, the \( x^2 \) term, and the \( x \) term shows that \( a_3 = a_2 = a_1 = 0 \). It follows that \( B \) is linearly independent and thus by 2.23 we have \( \dim U \geq 4 \). We also have \( \dim U \leq 5 \) by 2.38. However, it cannot be the case that \( \dim U = 5 \), since by \Cref{ex:1} this would imply that \( U = \poly_4(\R) \), but \( U \neq \poly_4(\R) \) since not all polynomials \( p \in \poly_4(\R) \) satisfy \( \int_{-1}^1 p = 0 \) . So \( \dim U = 4 \) and by 2.39 we may conclude that \( B \) is a basis of \( U \).

        \item We claim that \( 1 \not\in \Span\,B \). To see this, suppose that we have scalars \( a_1, a_2, a_3, a_4 \) such that
        \[
            a_1 x + a_2 (x^2 - \tfrac{1}{3}) + a_3 x^3 + a_4 (x^4 - \tfrac{1}{5}) = 1
        \]
        for each \( x \in \F \). The same argument used in part (a) shows that we must have \( a_4 = a_3 = a_2 = a_1 = 0 \) and so we arrive at the contradiction \( 0 = 1 \). Thus \( 1 \not\in \Span\,B \), so the list \( B' := 1, x, x^2 - \tfrac{1}{3}, x^3, x^4 - \tfrac{1}{5} \) is linearly independent by \href{https://lew98.github.io/Mathematics/LADR_Section_2_A_Exercises.pdf}{Exercise 2.A.11}. Then since \( \dim \poly_4(\R) = 5 \), 2.42 allows us to conclude that \( B' \) is a basis of \( \poly_4(\R) \).

        \item Let \( W = \Span(1) \). As the proof of 2.34 shows, we then have \( \poly_4(\R) = U \oplus W \).
    \end{enumerate}
\end{solution}

\begin{exercise}
\label{ex:9}
    Suppose \( v_1, \ldots, v_m \) is linearly independent in \( V \) and \( w \in V \). Prove that
    \[
        \dim \Span(v_1 + w, \ldots, v_m + w) \geq m - 1.
    \]
\end{exercise}

\begin{solution}
    Define \( B := v_2 - v_1, \ldots, v_m - v_1 \). We claim that \( B \) is linearly independent. To see this, suppose we have scalars \( a_2, \ldots, a_m \) such that
    \[
        a_2 (v_2 - v_1) + \cdots + a_m (v_m - v_1) = -(a_2 + \cdots + a_m) v_1 + a_2 v_2 + \cdots + a_m v_m = 0.
    \]
    Since the list \( v_1, \ldots, v_m \) is linearly independent, this implies that \( a_2 = \cdots = a_m = 0 \), whence \( B \) is linearly independent. Now observe that for any \( 2 \leq i \leq m \) we have
    \[
        v_i - v_1 = (v_i + w) - (v_1 + w) \in \Span(v_1 + w, \ldots, v_m + w).
    \]
    So we have shown that \( B \) is a list of \( m - 1 \) linearly independent vectors in \( \Span(v_1 + w, \ldots, v_m + w) \). Thus by 2.23 we have
    \[
        \dim \Span(v_1 + w, \ldots, v_m + w) \geq m - 1.
    \]
\end{solution}

\begin{exercise}
\label{ex:10}
    Suppose \( p_0, p_1, \ldots, p_m \in \poly(\F) \) are such that each \( p_j \) has degree \( j \). Prove that \( p_0, p_1, \ldots, p_m \) is a basis of \( \poly_m(\F) \).
\end{exercise}

\begin{solution}
    Let us show that the list \( p_0, p_1, \ldots, p_m \) is linearly independent. Suppose we have scalars \( a_0, a_1, \ldots, a_m \) such that
    \begin{equation}
        a_0 p_0(x) + a_1 p_1(x) + \cdots + a_m p_m(x) = 0
    \end{equation}
    for all \( x \in \F \). Suppose that \( c_m \) is the coefficient of \( x^m \) in the polynomial \( p_m \); we have \( c_m \neq 0 \) since \( p_m \) has degree \( m \). Since each \( p_j \) has degree \( j \), we see that the coefficient of \( x^m \) in the polynomial \( p_j \) for \( j < m \) must be zero. Hence the left-hand side of (1) has an \( a_m c_m x^m \) term whereas the right-hand side has no \( x^m \) term. It follows that \( a_m c_m = 0 \), and since \( c_m \neq 0 \), it must be the case that \( a_m = 0 \). Repeating this argument for the \( x^{m-1} \) term, then the \( x^{m-2} \) term, and so on, we find that \( a_0 = a_1 = \cdots = a_m = 0 \). Thus \( p_0, p_1, \ldots, p_m \) is linearly independent. Since this is a list of \( m + 1 \) linearly independent vectors in \( \poly_m(\F) \), which has dimension \( m + 1 \), 2.39 allows us to conclude that \( p_0, p_1, \ldots, p_m \) is a basis of \( \poly_m(\F) \).
\end{solution}

\begin{exercise}
\label{ex:11}
    Suppose that \( U \) and \( W \) are subspaces of \( \R^8 \) such that \( \dim U = 3, \dim W = 5, \) and \( U + W = \R^8 \). Prove that \( \R^8 = U \oplus W \).
\end{exercise}

\begin{solution}
    By 2.43, we have
    \[
        8 = \dim \R^8 = \dim (U + W) = \dim U + \dim W - \dim (U \cap W) = 8 - \dim (U \cap W).
    \]
    It follows that \( \dim (U \cap W) = 0 \) and hence that \( U \cap W = \{ 0 \} \). Then by 1.45, the sum \( U + W \) is direct.
\end{solution}

\begin{exercise}
\label{ex:12}
    Suppose \( U \) and \( W \) are both five-dimensional subspaces of \( \R^9 \). Prove that \( U \cap W \neq \{ 0 \} \).
\end{exercise}

\begin{solution}
    By 2.43, we have
    \[
        9 = \dim \R^9 \geq \dim (U + W) = \dim U + \dim W - \dim (U \cap W) = 10 - \dim (U \cap W).
    \]
    It follows that \( \dim (U \cap W) \geq 1 \) and hence that \( U \cap W \neq \{ 0 \} \).
\end{solution}

\begin{exercise}
\label{ex:13}
    Suppose \( U \) and \( W \) are both 4-dimensional subspaces of \( \C^6 \). Prove that there exist two vectors in \( U \cap W \) such that neither of these vectors is a scalar multiple of the other.
\end{exercise}

\begin{solution}
    By 2.43, we have
    \[
        6 = \dim \C^6 \geq \dim (U + W) = \dim U + \dim W - \dim (U \cap W) = 8 - \dim (U \cap W).
    \]
    It follows that \( \dim (U \cap W) \geq 2 \) and hence we can find a linearly independent list \( v_1, v_2 \) in \( U \cap W \). Then by \href{https://lew98.github.io/Mathematics/LADR_Section_2_A_Exercises.pdf}{Exercise 2.A.2 (b)}, neither one of these vectors is a scalar multiple of the other.
\end{solution}

\begin{exercise}
\label{ex:14}
    Suppose \( U_1, \ldots, U_m \) are finite-dimensional subspaces of \( V \). Prove that \( U_1 + \cdots + U_m \) is finite-dimensional and
    \[
        \dim (U_1 + \cdots + U_m) \leq \dim U_1 + \cdots + \dim U_m.
    \]
\end{exercise}

\begin{solution}
    Since each \( U_i \) is finite-dimensional, it has a basis \( B_i \), so that \( U_i = \Span\,B_i \). If we let \( B \) be the list of vectors \( B_1, B_2, \ldots, B_m \), then it is clear that \( U_1 + \cdots + U_m \) is spanned by \( B \). It follows that \( U_1 + \cdots + U_m \) is finite-dimensional. Since \( B \) has length \( \dim U_1 + \cdots + \dim U_m \), 2.23 implies that
    \[
        \dim (U_1 + \cdots + U_m) \leq \dim U_1 + \cdots + \dim U_m.
    \]
\end{solution}

\begin{exercise}
\label{ex:15}
    Suppose \( V \) is finite-dimensional, with \( \dim V = n \geq 1 \). Prove that there exist 1-dimensional subspaces \( U_1, \ldots, U_n \) of \( V \) such that
    \[
        V = U_1 \oplus \cdots \oplus U_n.
    \]
\end{exercise}

\begin{solution}
    Since \( n \geq 1 \), \( V \) has a non-empty basis \( u_1, \ldots, u_n \). Let \( U_i = \Span(u_i) \); since each \( u_i \neq 0 \), we have \( \dim U_i = 1 \). Then by the definition of a direct sum (1.40) and 2.29, which says that each vector in \( V \) is a unique linear combination of the basis vectors \( u_1, \ldots, u_n \), we have
    \[
        V = U_1 \oplus \cdots \oplus U_n.
    \]
\end{solution}

\begin{exercise}
\label{ex:16}
    Suppose \( U_1, \ldots, U_m \) are finite-dimensional subspaces of \( V \) such that \( U_1 + \cdots + U_m \) is a direct sum. Prove that \( U_1 \oplus \cdots \oplus U_m \) is finite-dimensional and
    \[
        \dim U_1 \oplus \cdots \oplus U_m = \dim U_1 + \cdots + \dim U_m.
    \]
    [\textit{The exercise above deepens the analogy between direct sums of subspaces and disjoint unions of subsets. Specifically, compare this exercise to the following obvious statement: if a set is written as a disjoint union of finite subsets, then the number of elements in the set equals the sum of the numbers of elements in the disjoint subsets.}]
\end{exercise}

\begin{solution}
    Since each \( U_i \) is finite-dimensional, it has a basis \( u^{(i)}_1, \ldots, u^{(i)}_{n_i} \). It is clear that the list
    \[
        u^{(1)}_1, \ldots, u^{(1)}_{n_1}, \ldots, u^{(m)}_1, \ldots, u^{(m)}_{n_m}
    \]
    spans \( U_1 \oplus \cdots \oplus U_m \), whence \( U_1 \oplus \cdots \oplus U_m \) is finite-dimensional. Suppose we have scalars \( a^{(1)}_1, \ldots, a^{(m)}_{n_m} \) such that
    \[
        a^{(1)}_1 u^{(1)}_1 + \cdots + a^{(1)}_{n_1} u^{(1)}_{n_1} + \cdots + a^{(m)}_1 u^{(m)}_1 + \ldots + a^{(m)}_{n_m} u^{(m)}_{n_m} = 0.
    \]
    Since \( a^{(i)}_1 u^{(i)}_1 + \cdots + a^{(i)}_{n_i} u^{(i)}_{n_i} \in U_i \) for each \( i \), and the sum \( U_1 \oplus \cdots \oplus U_m \) is direct, by 1.44 it must be the case that \( a^{(i)}_1 u^{(i)}_1 + \cdots + a^{(i)}_{n_i} u^{(i)}_{n_i} = 0 \) for each \( i \). Then since the list \( u^{(i)}_1, \ldots, u^{(i)}_{n_i} \) is linearly independent for each \( i \), we must have \( a^{(i)}_1 = \cdots = a^{(i)}_{n_i} = 0 \) for each \( i \). It follows that the list
    \[
        u^{(1)}_1, \ldots, u^{(1)}_{n_1}, \ldots, u^{(m)}_1, \ldots, u^{(m)}_{n_m}
    \]
    is linearly independent and hence is a basis of \( U_1 \oplus \cdots \oplus U_m \). Then since \( n_1 + \cdots + n_m = \dim U_1 + \cdots + \dim U_m \), we have
    \[
        \dim U_1 \oplus \cdots \oplus U_m = \dim U_1 + \cdots + \dim U_m.
    \]
\end{solution}

\begin{exercise}
\label{ex:17}
    You might guess, by analogy with the formula for the number of elements in the union of three subsets of a finite set, that if \( U_1, U_2, U_3 \) are subspaces of a finite-dimensional vector space, then
    \begin{align*}
        & \dim(U_1 + U_2 + U_3) \\
        & \hspace{18mm} = \dim U_1 + \dim U_2 + \dim U_3 \\
        & \hspace{22mm} - \dim(U_1 \cap U_2) - \dim(U_1 \cap U_3) - \dim(U_2 \cap U_3) \\
        & \hspace{22mm} + \dim(U_1 \cap U_2 \cap U_3).
    \end{align*}
    Prove this or give a counterexmaple.
\end{exercise}

\begin{solution}
    This is false. Consider the vector space \( \R^2 \) and suppose \( U_1, U_2, U_3 \) are three distinct lines through the origin. It is easily verified that \( U_1 + U_2 + U_3 = \R^2 \) and that \( U_1 \cap U_2 = U_1 \cap U_3 = U_2 \cap U_3 = U_1 \cap U_2 \cap U_3 = \{ 0 \} \). Then the left-hand side of the equation in question is 2, whereas the right-hand side is
    \[
        1 + 1 + 1 - 0 - 0 - 0 - 0 = 3 \neq 2.
    \]
\end{solution}

\noindent \hrulefill

\noindent \hypertarget{ladr}{\textcolor{blue}{[LADR]} Axler, S. (2015) \textit{Linear Algebra Done Right.} 3rd edn.}

\end{document}