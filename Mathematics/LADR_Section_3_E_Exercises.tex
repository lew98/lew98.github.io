\documentclass[12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{geometry}
\usepackage{amsfonts}
\usepackage{mathrsfs}
\usepackage{bm}
\usepackage{hyperref}
\usepackage[dvipsnames]{xcolor}
\usepackage{enumitem}
\usepackage{mathtools}
\usepackage{changepage}
\usepackage{lipsum}
\usepackage{tikz}
\usetikzlibrary{matrix}
\usepackage{tikz-cd}
\usepackage[nameinlink]{cleveref}
\geometry{
headheight=15pt,
left=60pt,
right=60pt
}
\setlength{\emergencystretch}{20pt}
\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhf{}
\lhead{}
\chead{Section 3.E Exercises}
\rhead{\thepage}
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    urlcolor=blue
}

\theoremstyle{definition}
\newtheorem*{remark}{Remark}

\newtheoremstyle{exercise}
    {}
    {}
    {}
    {}
    {\bfseries}
    {.}
    { }
    {\thmname{#1}\thmnumber{#2}\thmnote{ (#3)}}
\theoremstyle{exercise}
\newtheorem{exercise}{Exercise 3.E.}

\newtheoremstyle{solution}
    {}
    {}
    {}
    {}
    {\itshape\color{magenta}}
    {.}
    { }
    {\thmname{#1}\thmnote{ #3}}
\theoremstyle{solution}
\newtheorem*{solution}{Solution}

\Crefformat{exercise}{#2Exercise 3.E.#1#3}

\newcommand{\poly}{\mathcal{P}}
\newcommand{\lmap}{\mathcal{L}}
\newcommand{\mat}{\mathcal{M}}
\newcommand{\ts}{\textsuperscript}
\newcommand{\Span}{\text{span}}
\newcommand{\Null}{\text{null\,}}
\newcommand{\Range}{\text{range\,}}
\newcommand{\quand}{\quad \text{and} \quad}
\newcommand{\setcomp}[1]{#1^{\mathsf{c}}}
\newcommand{\N}{\mathbf{N}}
\newcommand{\Z}{\mathbf{Z}}
\newcommand{\Q}{\mathbf{Q}}
\newcommand{\R}{\mathbf{R}}
\newcommand{\C}{\mathbf{C}}
\newcommand{\F}{\mathbf{F}}

\DeclarePairedDelimiter\abs{\lvert}{\rvert}
% Swap the definition of \abs* and \norm*, so that \abs
% and \norm resizes the size of the brackets, and the 
% starred version does not.
\makeatletter
\let\oldabs\abs
\def\abs{\@ifstar{\oldabs}{\oldabs*}}
%
\let\oldnorm\norm
\def\norm{\@ifstar{\oldnorm}{\oldnorm*}}
\makeatother

\setlist[enumerate,1]{label={(\alph*)}}

\begin{document}

\section{Section 3.E Exercises}

Exercises with solutions from Section 3.E of \hyperlink{ladr}{[LADR]}.

\begin{exercise}
\label{ex:1}
    Suppose \( T \) is a function from \( V \) to \( W \). The \textit{\textbf{graph}} of \( T \) is the subset of \( V \times W \) defined by
    \[
        \text{graph of } T = \{ (v, Tv) \in V \times W : v \in V \}.
    \]
    Prove that \( T \) is a linear map if and only if the graph of \( T \) is a subspace of \( V \times W \).

    \vspace{2mm}

    \noindent [\textit{Formally, a function \( T \) from \( V \) to \( W \) is a subset \( T \) of \( V \times W \) such that for each \( v \in V \), there exists exactly one element \( (v, w) \in T \). In other words, formally a function is what is called above its graph. We do not usually think of functions in this formal manner. However, if we do become formal, then the exercise above could be rephrased as follows: Prove that a function \( T \) from \( V \) to \( W \) is a linear map if and only if \( T \) is a subspace of \( V \times W \).}]
\end{exercise}

\begin{solution}
    Let \( \mathsf{graph}(T) \) be the graph of \( T \). \( T \) is a linear map if and only if for all \( u, v \in V \) and \( \lambda \in \F \), one has \( T(u + \lambda v) = Tu + \lambda Tv \). This is equivalent to the statement that for all \( u, v \in V \) and \( \lambda \in \F \), one has \( (u + \lambda v, T(u + \lambda v)) = (u, Tu) + \lambda (v, Tv) \); this is exactly the statement that \( \mathsf{graph}(T) \) is a subspace of \( V \times W \). Symbolically:
    \begin{align*}
        T \in \lmap(V, W) &\iff (\forall (u, v, \lambda) \in V^2 \times \F)(T(u + \lambda v) = Tu + \lambda Tv) \\
        &\iff (\forall (u, v, \lambda) \in V^2 \times \F)((u + \lambda v, T(u + \lambda v)) = (u, Tu) + \lambda (v, Tv)) \\
        &\iff \mathsf{graph}(T) \leq V \times W.
    \end{align*}
\end{solution}

\begin{exercise}
\label{ex:2}
    Suppose \( V_1, \ldots, V_m \) are vector spaces such that \( V_1 \times \cdots \times V_m \) is finite-dimensional. Prove that \( V_j \) is finite-dimensional for each \( j = 1, \ldots, m \).
\end{exercise}

\begin{solution}
    Since \( V_1 \times \cdots \times V_m \) is finite-dimensional, it is spanned by some list \( \mathbf{v}_1, \ldots, \mathbf{v}_n \). For \( 1 \leq j \leq m \), define \( \text{proj}_j : V_1 \times \cdots \times V_m \to V_j \) by \( \text{proj}_j (v_1, \ldots, v_m) = v_j \); it is easily verified that \( \text{proj}_j \) is a surjective linear map. \href{https://lew98.github.io/Mathematics/LADR_Section_3_B_Exercises.pdf}{Exercise 3.B.10} now implies that the list \( \text{proj}_j \mathbf{v}_1, \ldots, \text{proj}_j \mathbf{v}_n \) spans \( V_j \) and we may conclude that \( V_j \) is finite-dimensional.
\end{solution}

\begin{exercise}
\label{ex:3}
    Give an example of a vector space \( V \) and subspaces \( U_1, U_2 \) of \( V \) such that \( U_1 \times U_2 \) is isomorphic to \( U_1 + U_2 \) but \( U_1 + U_2 \) is not a direct sum.

    \vspace{2mm}
    \noindent \textit{Hint:} The vector space \( V \) must be infinite-dimensional.
\end{exercise}

\begin{solution}
    Consider \( V = U_2 = \R^{\infty} \) and
    \[
        U_1 = \{ (x_1, 0, 0, \ldots) \in \R^{\infty} : x_1 \in \R \}.
    \]
    It is easily verified that \( U_1 + U_2 = \R^{\infty} \) and that this sum is not direct, since \( U_1 \cap U_2 \neq \{ 0 \} \). However, the map \( \Phi : U_1 \times U_2 \to \R^{\infty} \) given by
    \[
        \Phi((x_1, 0, 0, \ldots), (y_1, y_2, y_3, \ldots)) = (x_1, y_1, y_2, \ldots)
    \]
    is an isomorphism.
\end{solution}

\begin{exercise}
\label{ex:4}
    Suppose \( V_1, \ldots, V_m \) are vector spaces. Prove that \( \lmap(V_1 \times \cdots \times V_m, W) \) and \( \lmap(V_1, W) \times \cdots \times \lmap(V_m, W) \) are isomorphic vector spaces.
\end{exercise}

\begin{solution}
    Given a linear map \( T : V_1 \times \cdots \times V_m \to W \), for each \( 1 \leq j \leq m \) define a linear map \( T^{(j)} : V_j \to W \) by
    \[
        T^{(j)} v = T(0, \ldots, v, \ldots, 0),
    \]
    where the \( v \) is given as the \(j\)\ts{th} argument to \( T \), so that \( T^{(1)} v = T(v, 0, \ldots, 0), T^{(2)} v = T(0, v, 0, \ldots, 0), \) and so on. Define the map
    {\arraycolsep=1.8pt\def\arraystretch{1.5}
    \[
        \begin{array}{ccrcl}
            \Phi & : & \lmap(V_1 \times \cdots \times V_m, W) & \to & \lmap(V_1, W) \times \cdots \times \lmap(V_m, W) \\
            & & T & \mapsto & (T^{(1)}, \ldots, T^{(m)}).
        \end{array}
    \]}

    First, we claim that \( \Phi \) is linear. Let \( S, T \in \lmap(V_1 \times \cdots \times V_m, W) \) and \( \lambda \in \F \) be given. Then showing that \( \Phi \) is linear amounts to showing that
    \[
        ((S + \lambda T)^{(1)}, \ldots, (S + \lambda T)^{(m)}) = (S^{(1)}, \ldots, S^{(m)}) + \lambda (T^{(1)}, \ldots, T^{(m)}).
    \]
    It will suffice to show that for each \( 1 \leq j \leq m \) we have \( (S + \lambda T)^{(j)} = S^{(j)} + \lambda T^{(j)} \); each of these is a linear map \( V_j \to W \). Let \( v \in V_j \) be given. Then
    \begin{multline*}
        (S + \lambda T)^{(j)} v = (S + \lambda T)(0, \ldots, v, \ldots, 0) \\ = S(0, \ldots, v, \ldots, 0) + \lambda T(0, \ldots, v, \ldots, 0) = S^{(j)} v + \lambda T^{(j)} v.
    \end{multline*}
    Our claim follows.

    Next, we claim that \( \Phi \) is injective. Suppose \( T \in \lmap(V_1 \times \cdots \times V_m, W) \) is such that \( \Phi(T) = 0 \), i.e. \( T^{(1)} = \cdots = T^{(m)} = 0 \). Let \( (v_1, \ldots, v_m) \in V_1 \times \cdots \times V_m \) be given. Then
    \begin{multline*}
        T(v_1, \ldots, v_m) = T[(v_1, 0, \ldots, 0) + \cdots + (0, \ldots, 0, v_m)] \\ = T(v_1, 0, \ldots, 0) + \cdots + T(0, \ldots, 0, v_m) = T^{(1)} v_1 + \cdots + T^{(m)} v_m = 0.
    \end{multline*}
    Thus \( T = 0 \) and hence \( \Null \Phi = \{ 0 \} \), so that \( \Phi \) is injective.

    Finally, we claim that \( \Phi \) is surjective. Let \( (T_1, \ldots, T_m) \in \lmap(V_1, W) \times \cdots \times \lmap(V_m, W) \) be given, so that each \( T_j \) is a linear map \( V_j \to W \). Define \( T : V_1 \times \cdots \times V_m \to W \) by
    \[
        T(v_1, \ldots, v_m) = \sum_{i=1}^m T_i v_i.
    \]
    For any \( 1 \leq j \leq m \), we then have
    \[
        T^{(j)}v = T(0, \ldots, v, \ldots 0) = T_j v + \sum_{i \neq j} T_i(0) = T_j v.
    \]
    Thus \( \Phi(T) = (T_1, \ldots, T_m) \) and we see that \( \Phi \) is surjective. We may conclude that \( \Phi \) is an isomorphism.
\end{solution}

\begin{exercise}
\label{ex:5}
    Suppose \( W_1, \ldots, W_m \) are vector spaces. Prove that \( \lmap(V, W_1 \times \cdots \times W_m) \) and \( \lmap(V, W_1) \times \cdots \times \lmap(V, W_m) \) are isomorphic vector spaces.
\end{exercise}

\begin{solution}
    As in \Cref{ex:2}, for each \( 1 \leq j \leq m \), define \( \text{proj}_j : W_1 \times \cdots \times W_m \to W_j \) by \( \text{proj}_j (w_1, \ldots, w_m) = w_j \); it is easily verified that each \( \text{proj}_j \) is a linear map. Define the map
    {\arraycolsep=1.8pt\def\arraystretch{1.5}
    \[
        \begin{array}{ccrcl}
            \Phi & : & \lmap(V, W_1 \times \cdots \times W_m) & \to & \lmap(V, W_1) \times \cdots \times \lmap(V, W_m) \\
            & & T & \mapsto & (\text{proj}_1 \circ T, \ldots, \text{proj}_m \circ T).
        \end{array}
    \]}

    Verifying that the map \( \Phi \) is linear amounts to showing that for \( S, T \in \lmap(V, W_1 \times \cdots \times W_m), \lambda \in \F \), and \( 1 \leq j \leq m \), we have
    \[
        \text{proj}_j \circ (S + \lambda T) = (\text{proj}_j \circ S) + \lambda (\text{proj}_j \circ T);
    \]
    these are maps \( V \to W_j \). This follows from the linearity of \( \text{proj}_j \): for \( v \in V \), we have
    \[
        \text{proj}_j((S + \lambda T)(v)) = \text{proj}_j(Sv + \lambda Tv) = \text{proj}_j(Sv) + \lambda (\text{proj}_j(Tv)).
    \]
    Now define the map
    {\arraycolsep=1.8pt\def\arraystretch{1.5}
    \[
        \begin{array}{ccrcl}
            \Psi & : & \lmap(V, W_1) \times \cdots \times \lmap(V, W_m) & \to & \lmap(V, W_1 \times \cdots \times W_m) \\
            & & (T_1, \ldots, T_m) & \mapsto & (v \mapsto (T_1 v, \ldots, T_m v)).
        \end{array}
    \]}
    It is not hard to see that \( \Phi \) and \( \Psi \) are mutual inverses. It follows that \( \Phi \) is an isomorphism.
\end{solution}

\begin{exercise}
\label{ex:6}
    For \( n \) a positive integer, define \( V^n \) by
    \[
        V^n = \underbrace{V \times \cdots \times V}_{n \text{ times}}.
    \]
    Prove that \( V^n \) and \( \lmap(\F^n, V) \) are isomorphic vector spaces.
\end{exercise}

\begin{solution}
    For vector spaces \( V \) and \( W \), by \( V \cong W \) we mean that \( V \) is isomorphic to \( W \). It is not hard to see that if we have vector spaces \( V_1, \ldots, V_n \) and \( W_1, \ldots, W_n \) such that \( V_j \cong W_j \) for each \( 1 \leq j \leq n \), then \( V_1 \times \cdots \times V_n \cong W_1 \times \cdots \times W_n \). Combining this with \href{https://lew98.github.io/Mathematics/LADR_Section_3_D_Exercises.pdf}{Exercise 3.D.18}, we see that \( V^n \cong (\lmap(\F, V))^n \). Then \Cref{ex:4} gives us
    \[
        V^n \cong (\lmap(\F, V))^n \cong \lmap(\F^n, V).
    \]
\end{solution}

\begin{exercise}
\label{ex:7}
    Suppose \( v, x \) are vectors in \( V \) and \( U, W \) are subspaces of \( V \) such that \( v + U = x + W \). Prove that \( U = W \).
\end{exercise}

\begin{solution}
    Note that
    \begin{align*}
        u \in U &\iff v + u \in v + U \\
        &\iff (\exists w \in W)(v + u = x + w) \\
        &\iff (\exists w \in W)(u = (x - v) + w) \\
        &\iff u \in (x - v) + W.
    \end{align*}
    Thus \( U = (x - v) + W \). In particular, \( 0 = (x - v) + w \) for some \( w \in W \) and hence \( x - v \in W \). 3.85 now implies that \( (x - v) + W = W \) and we may conclude that \( U = W \).
\end{solution}

\begin{exercise}
\label{ex:8}
    Prove that a nonempty subset \( A \) of \( V \) is an affine subset of \( V \) if and only if \( \lambda v + (1 - \lambda) w \in A \) for all \( v, w \in A \) and all \( \lambda \in \F \).
\end{exercise}

\begin{solution}
    Suppose that \( A \) is an affine subset of \( V \), say \( A = x + U \) for some \( x \in V \) and some subspace \( U \) of \( V \). Suppose \( v, w \in A \) and \( \lambda \in \F \). Then \( v = x + u \) and \( w = x + u' \) for some \( u, u' \in U \). This implies that
    \[
        v - w = u - u' \in U \implies \lambda(v - w) \in U.
    \]
    Furthermore, \( w - x = u' \in U \) and so 3.85 gives us \( w + U = x + U = A \). It follows that
    \[
        \lambda v + (1 - \lambda)w = w + \lambda(v - w) \in w + U = A.
    \]

    Now suppose that \( A \) is a non-empty subset of \( V \) such that \( \lambda v + (1 - \lambda) w \in A \) for all \( v, w \in A \) and all \( \lambda \in \F \). Since \( A \) is non-empty, there exists some \( a \in A \). We claim that \( -a + A \) is a subspace of \( V \). We have \( -a + a = 0 \in -a + A \), so \( -a + A \) contains the zero vector. Let \( -a + v \in -a + A \) and \( \lambda \in \F \) be given. Then:
    \[
        \lambda(-a + v) = -\lambda a + \lambda v = -a + \lambda v + (1 - \lambda)a \in -a + A,
    \]
    where we have used our hypothesis that \( \lambda v + (1 - \lambda)a \in A \). Thus \( -a + A \) is closed under scalar multiplication. Suppose that \( -a + v, -a + w \in -a + A \). Then:
    \[
        (-a + v) + (-a + w) = 2 \left( -a + \tfrac{1}{2} v + \tfrac{1}{2} w \right) \in -a + A,
    \]
    where we have taken \( \lambda = \tfrac{1}{2} \) in \( \lambda v + (1 - \lambda)w \) to see that \( \tfrac{1}{2}v + \tfrac{1}{2} w \in A \), and used that \( -a + A \) is closed under scalar multiplication. Thus \( -a + A \) is also closed under vector addition and our claim follows. We may conclude that \( A = a + (-a + A) \) is an affine subset of \( A \).
\end{solution}

\begin{exercise}
\label{ex:9}
    Suppose \( A_1 \) and \( A_2 \) are affine subsets of \( V \). Prove that the intersection \( A_1 \cap A_2 \) is either an affine subset of \( V \) or the empty set.
\end{exercise}

\begin{solution}
    Suppose \( A_1 = v_1 + U_1 \) and \( A_2 = v_2 + U_2 \), where \( v_1, v_2 \in V \) and \( U_1, U_2 \) are subspaces of \( V \). Suppose that \( A_1 \cap A_2 \) is non-empty, so that there exists some \( w \in A_1 \cap A_2 \). Then by 3.85 we have \( A_1 = w + U_1 \) and \( A_2 = w + U_2 \). We claim that
    \[
        A_1 \cap A_2 = w + (U_1 \cap U_2).
    \]
    If \( x \in A_1 \cap A_2 \), then \( x = w + u_1 \) and \( x = w + u_2 \) for some \( u_1 \in U_1 \) and \( u_2 \in U_2 \). This implies that \( u_1 = u_2 \in U_1 \cap U_2 \) and thus \( x \in w + (U_1 \cap U_2) \). Conversely, if \( x \in w + (U_1 \cap U_2) \) then \( x = w + u \) where \( u \in U_1 \cap U_2 \) and thus \( x \in A_1 \) and \( x \in A_2 \). Our claim follows and hence we see that \( A_1 \cap A_2 \) is an affine subset of \( V \).
\end{solution}

\begin{exercise}
\label{ex:10}
    Prove that the intersection of every collection of affine subsets of \( V \) is either an affine subset of \( V \) or the empty set.
\end{exercise}

\begin{solution}
    Suppose we have a collection \( \{ A_i : i \in I \} \) of affine subsets of \( V \), say \( A_i = v_i + U_i \) for some \( v_i \in V \) and some subspace \( U_i \) of \( V \). Let \( \mathscr{A} = \bigcap_{i \in I} A_i \) and suppose that \( \mathscr{A} \) is non-empty, so that there exists some \( w \in \mathscr{A} \). Then by 3.85 we have \( A_i = w + U_i \) for each \( i \in I \). Let \( \mathscr{U} = \bigcap_{i \in I} U_i \). We claim that
    \[
        \mathscr{A} = w + \mathscr{U}.
    \]
    If \( x \in \mathscr{A} \), then for each \( i \in I \) we have \( x = w + u_i \) for some \( u_i \in U_i \). For all \( i, j \in I \) we have by cancellation that \( u_i = u_j \) and thus this single vector belongs to \( \mathscr{U} \), so that \( x \in w + \mathscr{U} \). Conversely, if \( x \in w + \mathscr{U} \) then \( x = w + u \) where \( u \in \mathscr{U} \). Then for any given \( i \in I \), we have \( x = w + u \in A_i \) since \( u \in U_i \). Our claim follows and hence \( \mathscr{U} \) is an affine subset of \( V \). (\(\mathscr{U}\) is a subspace of \( V \) by \href{https://lew98.github.io/Mathematics/LADR_Section_1_C_Exercises.pdf}{Exercise 1.C.11}.)
\end{solution}

\begin{exercise}
\label{ex:11}
    Suppose \( v_1, \ldots, v_m \in V \). Let
    \[
        A = \{ \lambda_1 v_1 + \cdots + \lambda_m v_m : \lambda_1, \ldots, \lambda_m \in \F \text{ and } \lambda_1 + \cdots + \lambda_m = 1\}.
    \]
    \begin{enumerate}
        \item Prove that \( A \) is an affine subset of \( V \).

        \item Prove that every affine subset of \( V \) that contains \( v_1, \ldots, v_m \) also contains \( A \).

        \item Prove that \( A = v + U \) for some \( v \in V \) and some subspace \( U \) of \( V \) with \( \dim U \leq m - 1 \).
    \end{enumerate}
\end{exercise}

\begin{solution}
    \begin{enumerate}
        \item Suppose \( v = \sum_{j=1}^m \lambda_j v_j \) and \( w = \sum_{j=1}^m \mu_j v_j \) belong to \( A \) and \( \gamma \in \F \). Then:
        \[
            \gamma v + (1 - \gamma) w = \gamma \sum_{j=1}^m \lambda_j v_j + (1 - \gamma) \sum_{j=1}^m \mu_j v_j = \sum_{j=1}^m [\gamma \lambda_j + (1 - \gamma) \mu_j] v_j.
        \]
        Note that
        \[
            \sum_{j=1}^m [\gamma \lambda_j + (1 - \gamma) \mu_j] = \gamma \sum_{j=1}^m \lambda_j + (1 - \gamma) \sum_{j=1}^m \mu_j = \gamma + (1 - \gamma) = 1.
        \]
        It follows that \( \gamma v + (1 - \gamma) w \in A \) and hence by \Cref{ex:8} we may conclude that \( A \) is an affine subset of \( V \).

        \item Suppose that \( v + U \) is an affine subset of \( V \) which contains \( v_1, \ldots, v_m \), i.e.\ \( v_j = v + u_j \) for some \( u_j \in U \). Suppose that \( \sum_{j=1}^m \lambda_j v_j \in A \). Then
        \[
            \sum_{j=1}^m \lambda_j v_j = \sum_{j=1}^m \lambda_j (v + u_j) = \left(\sum_{j=1}^m \lambda_j\right) v + \sum_{j=1}^m \lambda_j u_j = v + \sum_{j=1}^m \lambda_j u_j \in v + U.
        \]
        Thus \( A \subseteq v + U \).

        \item If \( m = 1 \) then \( A = \{ v_1 \} = v_1 + \{ 0 \} \). If \( m \geq 2 \), then let \( U = \Span(v_2 - v_1, \ldots, v_m - v_1) \) and note that \( \dim U \leq m - 1 \). Then \( v_1 + U \) is an affine subset of \( V \) that contains \( v_1, \ldots, v_m \) and so by part (b) we have \( A \subseteq v_1 + U \). Suppose that \( v_1 + a_2(v_2 - v_1) + \cdots + a_m(v_m - v_1) \in v_1 + U \). Note that
        \[
            v_1 + a_2(v_2 - v_1) + \cdots + a_m(v_m - v_1) = (1 - (a_2 + \cdots + a_m))v_1 + a_2 v_2 + \cdots + a_m v_m \in A.
        \]
        Thus \( v_1 + U \subseteq A \) and we may conclude that \( A = v_1 + U \).
    \end{enumerate}
\end{solution}

\begin{exercise}
\label{ex:12}
    Suppose \( U \) is a subspace of \( V \) such that \( V/U \) is finite-dimensional. Prove that \( V \) is isomorphic to \( U \times (V/U) \).
\end{exercise}

\begin{solution}
    Let \( v_1 + U, \ldots, v_m + U \) be a basis of \( V/U \). Define a linear map \( T : V/U \to V \) by \( T(v_j + U) = v_j \) and a map \( S : U \times (V/U) \to V \) by \( S(u, v + U) = u + T(v + U) \); the linearity of \( T \) implies the linearity of \( S \). We claim that \( S \) is injective. Suppose that \( (u, v + U) \in U \times (V/U) \) is such that \( S(u, v + U) = u + T(v + U) = 0 \). Since \( v_1 + U, \ldots, v_m + U \) spans \( V/U \), the list \( v_1, \ldots, v_m \) spans \( \Range T \). Thus there are scalars \( a_1, \ldots, a_m \) such that \( T(v + U) = a_1 v_1 + \cdots a_m v_m \), which implies that
    \[
        a_1 v_1 + \cdots + a_m v_m = -u \in U.
    \]
    Applying the quotient map \( \pi \) to both sides of this equality gives
    \[
        a_1 (v_1 + U) + \cdots + a_m (v_m + U) = 0.
    \]
    The linear independence of the basis \( v_1 + U, \ldots, v_m + U \) then gives \( a_1 = \cdots = a_m = 0 \) and hence \( T(v + U) = 0 \). It follows that \( u = 0 \) and thus \( \Null S = \{ 0 \} \), i.e.\ \( S \) is injective.

    Now we claim that \( S \) is surjective. Let \( v \in V \) be given. There are scalars \( a_1, \ldots, a_m \) such that \( v + U = a_1 (v_1 + U) + \cdots + a_m (v_m + U) \). In particular,
    \[
        v = a_1 (v_1 + u_1) + \cdots + a_m (v_m + u_m) = \sum_{j=1}^m a_j u_j + \sum_{j=1}^m a_j v_j, 
    \]
    for some vectors \( u_1, \ldots, u_m \) in \( U \). Observe that
    \[
        S \left( \sum_{j=1}^m a_j u_j, \sum_{j=1}^m a_j v_j + U \right) = \sum_{j=1}^m a_j u_j + \sum_{j=1}^m a_j v_j = v.
    \]
    Thus \( S \) is surjective and we may conclude that \( S \) is an isomorphism.
\end{solution}

\begin{exercise}
\label{ex:13}
    Suppose \( U \) is a subspace of \( V \) and \( v_1 + U, \ldots, v_m + U \) is a basis of \( V/U \) and \( u_1, \ldots, u_n \) is a basis of \( U \). Prove that \( v_1, \ldots, v_m, u_1, \ldots, u_n \) is a basis of \( V \).
\end{exercise}

\begin{solution}
    First, let us prove the following lemma.

    \vspace{2mm}

    \noindent \textbf{Lemma 1.} Suppose \( T : V \to W \) is an isomorphism. If \( v_1, \ldots, v_m \) is a basis of \( V \), then \( Tv_1, \ldots, Tv_m \) is a basis of \( W \).

    \vspace{2mm}

    \noindent \textit{Proof.} This follows from \href{https://lew98.github.io/Mathematics/LADR_Section_3_B_Exercises.pdf}{Exercise 3.B.9} and \href{https://lew98.github.io/Mathematics/LADR_Section_3_B_Exercises.pdf}{Exercise 3.B.10}.

    \vspace{2mm}

    As the proof of 3.76 shows, the list \( (v_1 + U, 0), \ldots, (v + U_m, 0), (0, u_1), \ldots, (0, u_n) \) is a basis of \( (V/U) \times U \). Taking the isomorphism \( S \) from the solution to \Cref{ex:12}, but swapping the arguments, we have by Lemma 1 that the list \( S(v_1 + U, 0), \ldots, S(v_m + U, 0), S(0, u_1), \ldots, S(0, u_n) \) is a basis of \( V \). This list is nothing but \( v_1, \ldots, v_m, u_1, \ldots, u_n \).
\end{solution}

\begin{exercise}
\label{ex:14}
    Suppose \( U = \{ (x_1, x_2, \ldots) \in \F^{\infty} : x_j \neq 0 \text{ for only finitely many } j \} \).
    \begin{enumerate}
        \item Show that \( U \) is a subspace of \( \F^{\infty} \).

        \item Prove that \( \F^{\infty} / U \) is infinite-dimensional.
    \end{enumerate}
\end{exercise}

\begin{solution}
    \begin{enumerate}
        \item Note that \( U \) consists precisely of those sequences \( (x_n) \in \F^{\infty} \) such that there exists an \( N \in \N \) such that \( x_n = 0 \) for all \( n \geq N \). The zero vector in \( \F^{\infty} \) certainly satisfies this property. Suppose \( (x_n) \) and \( (y_n) \) belong to \( U \) and \( \lambda \in \F \). There are positive integers \( M \) and \( N \) such that \( x_n = 0 \) for all \( n \geq M \) and \( y_n = 0 \) for all \( n \geq N \). Set \( K = \max \{ M, N \} \). Then for all \( n \geq K \) we have \( x_n + \lambda y_n = 0 \). It follows that \( (x_n) + \lambda (y_n) \) belongs to \( U \) and hence \( U \) is a subspace of \( \F^{\infty} \).

        \item For \( x \in \F^{\infty} \), we will use the notation \( x(n) \) to denote the \( n \)\ts{th} term of \( x \). Let \( e_j \in \F^{\infty} \) be the sequence given by
        \[
            e_j(n) = \begin{cases}
                1 & \text{if } n \text{ is divisible by } 2^j, \\
                0 & \text{otherwise},
            \end{cases}
        \]
        i.e.\
        \begin{align*}
            e_1 &= (0, 1, 0, 1, 0, 1, 0, 1, \ldots), \\
            e_2 &= (0, 0, 0, 1, 0, 0, 0, 1, \ldots), \\
            e_3 &= (0, 0, 0, 0, 0, 0, 0, 1, \ldots), \text{ etc}.
        \end{align*}
        Let \( m \in \N \) be given. We claim that the list \( e_1 + U, \ldots, e_m + U \) is linearly independent. Suppose we have scalars \( a_1, \ldots, a_m \) such that
        \[
            a_1 (e_1 + U) + \cdots + a_m (e_m + U) = (a_1 e_1 + \cdots + a_m e_m) + U = 0.
        \]
        This is the case if and only if \( a_1 e_1 + \cdots + a_m e_m \in U \). Letting \( e = a_1 e_1 + \cdots + a_m e_m \), there is a positive integer \( N \) such that \( e(n) = 0 \) for all \( n \geq N \). Let \( K \in \N \) be such that \( 2^{mK} \geq N \) and note that we have \( e_1(2^{mK}) = \cdots = e_m(2^{mK}) = 1 \). It follows that \( e_1(2^{mK} + 2) = 1 \) and \( e_2(2^{mK} + 2) = \cdots = e_m(2^{mK} + 2) = 0 \). Thus
        \[
            e(2^{mK} + 2) = a_1 e_1(2^{mK} + 2) = a_1 = 0.
        \]
        Similarly, \( e_1(2^{mK} + 2^2) = e_2(2^{mK} + 2^2) = 1 \) and \( e_3(2^{mK} + 2^2) = \cdots = e_m(2^{mK} + 2^2) = 0 \) and thus
        \[
            e(2^{mK} + 2^2) = a_1 + a_2 = a_2 = 0.
        \]
        Continuing in this manner, we see that \( a_1 = \cdots = a_m = 0 \) and our claim follows.

        \href{https://lew98.github.io/Mathematics/LADR_Section_2_A_Exercises.pdf}{Exercise 2.A.14} now shows that \( \F^{\infty} / U \) is infinite-dimensional.
    \end{enumerate}
\end{solution}

\begin{exercise}
\label{ex:15}
    Suppose \( \varphi \in \lmap(V, \F) \) and \( \varphi \neq 0 \). Prove that \( \dim V/(\Null \varphi) = 1 \).
\end{exercise}

\begin{solution}
    Since \( \varphi \neq 0 \), there is some \( u \in V \) such that \( \varphi(u) \neq 0 \). For any \( \lambda \in \F \), observe that
    \[
        \varphi \left( \frac{\lambda}{\varphi(u)} u \right) = \lambda.
    \]
    Thus \( \varphi \) is surjective and so by 3.91 we have \( V / (\Null \varphi) \cong \F \). It follows that \( \dim V/(\Null \varphi) = \dim \F = 1 \).
\end{solution}

\begin{exercise}
\label{ex:16}
    Suppose \( U \) is a subspace of \( V \) such that \( \dim V/U = 1 \). Prove that there exists \( \varphi \in \lmap(V, \F) \) such that \( \Null \varphi = U \).
\end{exercise}

\begin{solution}
    Since \( \dim V/U = 1 \), there is some \( w \in V \) such that \( V/U = \{ aw + U : a \in \F \} \). So for \( v \in V \), we have \( v + U = aw + U \) for some unique \( a \in \F \). Define \( \varphi : V \to \F \) by \( \varphi(v) = a \). Suppose \( v_1, v_2 \in V \) and \( \lambda \in \F \). Then \( v_1 + U = a_1 w + U \) and \( v_2 + U = a_2 w + U \) for some scalars \( a_1 \) and \( a_2 \). Observe that
    \[
        (v_1 + \lambda v_2) + U = (v_1 + U) + \lambda (v_2 + U) = (a_1 w + U) + \lambda (a_2 w + U) = (a_1 + \lambda a_2) w + U.
    \]
    It follows that
    \[
        \varphi(v_1 + \lambda v_2) = a_1 + \lambda a_2 = \varphi(v_1) + \lambda \varphi(v_2).
    \]
    Thus \( \varphi \) is linear. By 3.85, we have
    \[
        \varphi(v) = 0 \iff v + U = 0 + U \iff v \in U.
    \]
    Thus \( \Null \varphi = U \).
\end{solution}

\begin{exercise}
\label{ex:17}
    Suppose \( U \) is a subspace of \( V \) such that \( V/U \) is finite-dimensional. Prove that there exists a subspace \( W \) of \( V \) such that \( \dim W = \dim V/U \) and \( V = U \oplus W \).
\end{exercise}

\begin{solution}
    Let \( v_1 + U, \ldots, v_m + U \) be a basis of \( V/U \). As in \Cref{ex:12}, take the linear map \( T : V/U \to V \) given by \( T(v_j + U) = v_j \) and define \( W = \Span(v_1, \ldots, v_m) \). Clearly, \( \Range T = W \). Since the list \( \pi(v_1) = v_1 + U, \ldots, \pi(v_m) = v_m + U \) is linearly independent, \href{https://lew98.github.io/Mathematics/LADR_Section_3_A_Exercises.pdf}{Exercise 3.A.4} shows that the list \( v_1, \ldots, v_m \) is linearly independent. Suppose that \( v + U = (a_1 v_1 + \cdots + a_m v_m) + U \) is such that \( T(v + U) = a_1 v_1 + \cdots + a_m v_m = 0 \). The linear independence of the list \( v_1, \ldots, v_m \) gives us \( a_1 = \cdots = a_m = 0 \) and thus \( v + U = 0 \). Hence \( T \) is injective and we see that \( T : V/U \to W \) is an isomorphism; it follows that \( \dim W = \dim V/U \).

    Let \( v \in V \) be given. Then \( v + U = (a_1 v_1 + \cdots + a_m v_m) + U \) for some \( a_1 v_1 + \cdots + a_m v_m \in W \). In particular,
    \[
        v = u + a_1 v_1 + \cdots + a_m v_m \in U + W
    \]
    for some \( u \in U \). Thus \( V = U + W \). Now suppose that \( v \in U \cap W \). Then \( v = a_1 v_1 + \cdots + a_m v_m \) for some scalars \( a_1, \ldots, a_m \), which gives us
    \[
        v + U = (a_1 v_1 + \cdots + a_m v_m) + U = a_1 (v_1 + U) + \cdots + a_m (v_m + U).
    \]
    Since \( v \in U \) we must also have \( v + U = 0 + U \). The linear independence of the basis \( v_1 + U, \ldots, v_m + U \) then implies that \( a_1 = \cdots = a_m = 0 \) and hence that \( v = 0 \). Thus \( U \cap W = \{ 0 \} \) and we see that the sum \( V = U \oplus W \) is direct.
\end{solution}

\begin{exercise}
\label{ex:18}
    Suppose \( T \in \lmap(V, W) \) and \( U \) is a subspace of \( V \). Let \( \pi \) denote the quotient map from \( V \) onto \( V/U \). Prove that there exists \( S \in \lmap(V/U, W) \) such that \( T = S \circ \pi \) if and only if \( U \subset \Null T \).
\end{exercise}

\begin{solution}
    Suppose there exists such an \( S \) and suppose \( u \in U \). Then
    \[
        Tu = S(\pi(u)) = S(0 + U) = 0.
    \]
    Thus \( U \subseteq \Null T \).

    Now suppose that \( U \subseteq \Null T \). Define \( S : V/U \to W \) by \( S(v + U) = Tv \). This map is well-defined: if \( v + U = w + U \) then by 3.85 we must have \( v - w \in U \subseteq \Null T \), so that \( Tv = Tw \). The linearity of \( S \) follows from the linearity of \( T \) and evidently we have \( T = S \circ \pi \).
\end{solution}

\begin{exercise}
\label{ex:19}
    Find a correct statement analogous to 3.78 that is applicable to finite sets, with unions analogous to sums of subspaces and disjoint unions analogous to direct sums.
\end{exercise}

\begin{solution}
    Let \( \abs{A} \) denote the number of elements in a finite set \( A \). Suppose \( A_1, \ldots, A_m \) are finite sets. Then the sets \( A_1, \ldots, A_m \) are pairwise disjoint if and only if
    \[
        \abs{A_1 \cup \cdots \cup A_m} = \abs{A_1} + \cdots + \abs{A_m}.
    \]
\end{solution}

\begin{exercise}
\label{ex:20}
    Suppose \( U \) is a subspace of \( V \). Define \( \Gamma : \lmap(V/U, W) \to \lmap(V, W) \) by
    \[
        \Gamma(S) = S \circ \pi.
    \]
    \begin{enumerate}
        \item Show that \( \Gamma \) is a linear map.

        \item Show that \( \Gamma \) is injective.

        \item Show that \( \Range \Gamma = \{ T \in \lmap(V, W) : Tu = 0 \text{ for every } u \in U \} \).
    \end{enumerate}
\end{exercise}

\begin{solution}
    \begin{enumerate}
        \item Suppose \( S, T \in \lmap(V/U, W), \lambda \in \F \) and \( v \in V \). Then
        \[
            \Gamma(S + \lambda T)(v) = (S + \lambda T)(v + U) = S(v + U) + \lambda T(v + U) = \Gamma(S)(v) + \lambda \Gamma(T)(v).
        \]
        Thus \( \Gamma(S + \lambda T) = \Gamma(S) + \lambda \Gamma(T) \), i.e.\ \( \Gamma \) is linear.

        \item Suppose that \( S \in \lmap(V/U, W) \) is such that \( \Gamma(S) = 0 \), i.e.\ \( S(v + U) = 0 \) for all \( v \in V \). Then \( S = 0 \) and thus \( \Null \Gamma = \{ 0 \} \), i.e.\ \( \Gamma \) is injective.

        \item Let \( A = \{ T \in \lmap(V, W) : Tu = 0 \text{ for every } u \in U \} \). Suppose \( S \in \lmap(V/U, W) \) and \( u \in U \). Then
        \[
            \Gamma(S)(u) = S(\pi(u)) = S(0 + U) = 0.
        \]
        Thus \( \Gamma(S) \in A \), so that \( \Range \Gamma \subseteq A \). Suppose \( T \in A \), i.e.\ \( U \subseteq \Null T \). By \Cref{ex:18}, there exists an \( S \in \lmap(V/U, W) \) such that \( T = S \circ \pi = \Gamma(S) \). Hence \( A \subseteq \Range \Gamma \) and we may conclude that \( \Range \Gamma = A \).
    \end{enumerate}
\end{solution}

\noindent \hrulefill

\noindent \hypertarget{ladr}{\textcolor{blue}{[LADR]} Axler, S. (2015) \textit{Linear Algebra Done Right.} 3\ts{rd} edition.}

\end{document}